{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c25d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e9055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our training data and take the first column as the index column\n",
    "fraud_train = pd.read_csv('fraudTrain.csv', index_col=0)\n",
    "\n",
    "# split the training data into x and y\n",
    "X = fraud_train.drop(columns='is_fraud')\n",
    "y = fraud_train['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652b9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   cc_num                 1296675 non-null  int64  \n",
      " 2   merchant               1296675 non-null  object \n",
      " 3   category               1296675 non-null  object \n",
      " 4   amt                    1296675 non-null  float64\n",
      " 5   first                  1296675 non-null  object \n",
      " 6   last                   1296675 non-null  object \n",
      " 7   gender                 1296675 non-null  object \n",
      " 8   street                 1296675 non-null  object \n",
      " 9   city                   1296675 non-null  object \n",
      " 10  state                  1296675 non-null  object \n",
      " 11  zip                    1296675 non-null  int64  \n",
      " 12  lat                    1296675 non-null  float64\n",
      " 13  long                   1296675 non-null  float64\n",
      " 14  city_pop               1296675 non-null  int64  \n",
      " 15  job                    1296675 non-null  object \n",
      " 16  dob                    1296675 non-null  object \n",
      " 17  trans_num              1296675 non-null  object \n",
      " 18  unix_time              1296675 non-null  int64  \n",
      " 19  merch_lat              1296675 non-null  float64\n",
      " 20  merch_long             1296675 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(12)\n",
      "memory usage: 217.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94102</th>\n",
       "      <td>2019-02-25 08:24:40</td>\n",
       "      <td>374497717543058</td>\n",
       "      <td>fraud_Funk Group</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>20.00</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Hurst</td>\n",
       "      <td>F</td>\n",
       "      <td>31701 Tucker Square Suite 893</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>...</td>\n",
       "      <td>58579</td>\n",
       "      <td>47.1709</td>\n",
       "      <td>-100.7944</td>\n",
       "      <td>1190</td>\n",
       "      <td>Designer, ceramics/pottery</td>\n",
       "      <td>1948-06-30</td>\n",
       "      <td>1595dec12f6f19ceaae9b7df0f8af5c0</td>\n",
       "      <td>1330158280</td>\n",
       "      <td>46.398331</td>\n",
       "      <td>-99.813959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198791</th>\n",
       "      <td>2019-04-12 19:50:15</td>\n",
       "      <td>4428154703770710</td>\n",
       "      <td>fraud_Prosacco, Kreiger and Kovacek</td>\n",
       "      <td>home</td>\n",
       "      <td>284.88</td>\n",
       "      <td>Brittany</td>\n",
       "      <td>Guerra</td>\n",
       "      <td>F</td>\n",
       "      <td>79209 Gary Dale</td>\n",
       "      <td>Colton</td>\n",
       "      <td>...</td>\n",
       "      <td>99113</td>\n",
       "      <td>46.5901</td>\n",
       "      <td>-117.1692</td>\n",
       "      <td>761</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>1943-06-30</td>\n",
       "      <td>0ed26b649ed0fce94d8e632b7208dea0</td>\n",
       "      <td>1334260215</td>\n",
       "      <td>45.687331</td>\n",
       "      <td>-117.488135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238587</th>\n",
       "      <td>2020-05-31 21:50:53</td>\n",
       "      <td>213148039875802</td>\n",
       "      <td>fraud_Langworth, Boehm and Gulgowski</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>5.07</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Jacobs</td>\n",
       "      <td>F</td>\n",
       "      <td>034 Kimberly Mountains</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>...</td>\n",
       "      <td>33510</td>\n",
       "      <td>27.9551</td>\n",
       "      <td>-82.2966</td>\n",
       "      <td>79613</td>\n",
       "      <td>Environmental consultant</td>\n",
       "      <td>1978-11-30</td>\n",
       "      <td>7096316ec1a4b261e8613013827abae7</td>\n",
       "      <td>1370037053</td>\n",
       "      <td>27.254081</td>\n",
       "      <td>-81.974799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_date_trans_time            cc_num  \\\n",
       "94102     2019-02-25 08:24:40   374497717543058   \n",
       "198791    2019-04-12 19:50:15  4428154703770710   \n",
       "1238587   2020-05-31 21:50:53   213148039875802   \n",
       "\n",
       "                                     merchant      category     amt     first  \\\n",
       "94102                        fraud_Funk Group   grocery_net   20.00     Linda   \n",
       "198791    fraud_Prosacco, Kreiger and Kovacek          home  284.88  Brittany   \n",
       "1238587  fraud_Langworth, Boehm and Gulgowski  shopping_net    5.07      Jill   \n",
       "\n",
       "           last gender                         street     city  ...    zip  \\\n",
       "94102     Hurst      F  31701 Tucker Square Suite 893   Wilton  ...  58579   \n",
       "198791   Guerra      F                79209 Gary Dale   Colton  ...  99113   \n",
       "1238587  Jacobs      F         034 Kimberly Mountains  Brandon  ...  33510   \n",
       "\n",
       "             lat      long  city_pop                         job         dob  \\\n",
       "94102    47.1709 -100.7944      1190  Designer, ceramics/pottery  1948-06-30   \n",
       "198791   46.5901 -117.1692       761     Chief Marketing Officer  1943-06-30   \n",
       "1238587  27.9551  -82.2966     79613    Environmental consultant  1978-11-30   \n",
       "\n",
       "                                trans_num   unix_time  merch_lat  merch_long  \n",
       "94102    1595dec12f6f19ceaae9b7df0f8af5c0  1330158280  46.398331  -99.813959  \n",
       "198791   0ed26b649ed0fce94d8e632b7208dea0  1334260215  45.687331 -117.488135  \n",
       "1238587  7096316ec1a4b261e8613013827abae7  1370037053  27.254081  -81.974799  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at our data\n",
    "X.info()\n",
    "X.sample(3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f775f22",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## 1. Finding and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01dbe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what columns have null values?\n",
    "sum(X.isnull().sum()) + y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5586ff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what columns have missing/na values?\n",
    "sum(X.isna().sum()) + y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42263e5e",
   "metadata": {},
   "source": [
    "No handling of missing values is required as there are no missing values in our trainng dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33756333",
   "metadata": {},
   "source": [
    "## 2. Finding and Removing Outliers\n",
    "\n",
    "Removing outliers is an important part of preprocessing as it can:\n",
    "- distort data analysis \n",
    "- reduce machine learning model accuracy and generalization\n",
    "- impact visual data, skewing the scale \n",
    "- more?\n",
    "\n",
    "For numeric columns (those with an integer or float data type), I chose to use the [Interquartile Range Method](https://online.stat.psu.edu/stat200/lesson/3/3.2) of finding and removing outliers. \n",
    "\n",
    "Categorical, or \n",
    "\n",
    "## FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16038acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the numerical columns\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_cols\n",
    "\n",
    "# calculate the IQR lower and upper bounds for each numerical column\n",
    "def iqr_bounds(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb56025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_num: lower=-6513275846701038.0, upper=1.133557426847813e+16\n",
      "amt: lower=-100.58499999999998, upper=193.375\n",
      "zip: lower=-42470.5, upper=140749.5\n",
      "lat: lower=23.640650000000004, upper=52.920249999999996\n",
      "long: lower=-121.75800000000001, upper=-55.198\n",
      "city_pop: lower=-28634.5, upper=49705.5\n",
      "unix_time: lower=1307798793.0, upper=1390337325.0\n",
      "merch_lat: lower=23.898184000000008, upper=52.79255199999999\n",
      "merch_long: lower=-121.88799400000002, upper=-55.24607799999998\n"
     ]
    }
   ],
   "source": [
    "# lets look at the lower and upper bounds for each numerical column\n",
    "for col in num_cols:\n",
    "    lower, upper = iqr_bounds(X[col])\n",
    "    print(f\"{col}: lower={lower}, upper={upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a261fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_num: 118789 outliers\n",
      "amt: 67290 outliers\n",
      "zip: 0 outliers\n",
      "lat: 4679 outliers\n",
      "long: 49922 outliers\n",
      "city_pop: 242674 outliers\n",
      "unix_time: 0 outliers\n",
      "merch_lat: 4967 outliers\n",
      "merch_long: 41994 outliers\n"
     ]
    }
   ],
   "source": [
    "# how many outliers are there in each numerical column?\n",
    "for col in num_cols:\n",
    "    lower, upper = iqr_bounds(X[col])\n",
    "    outliers = fraud_train[(fraud_train[col] < lower) | (fraud_train[col] > upper)]\n",
    "    print(f\"{col}: {len(outliers)} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61143c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdddcae0",
   "metadata": {},
   "source": [
    "I won't be dropping the rows with outlier values before training a model on the dataset, as I'm interested in seeing how the model performs with and without the outlier values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6447216",
   "metadata": {},
   "source": [
    "### 3. Correlation Analysis & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133ab60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db5d0dbf",
   "metadata": {},
   "source": [
    "### Other Preprocessing Steps\n",
    "\n",
    "The trans_date_trans_time column may not help us detect fraud very well, but there is some interesting information we may want to look at within the column. Information such as day of the week or the hour in which the transaction took place could help us identify fraudulent transactions more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5f3d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_day_of_week</th>\n",
       "      <th>trans_hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296670</th>\n",
       "      <td>2020-06-21 12:12:08</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296671</th>\n",
       "      <td>2020-06-21 12:12:19</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296672</th>\n",
       "      <td>2020-06-21 12:12:32</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296673</th>\n",
       "      <td>2020-06-21 12:13:36</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296674</th>\n",
       "      <td>2020-06-21 12:13:37</td>\n",
       "      <td>June</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296675 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_date_trans_time trans_month trans_day_of_week  trans_hour_of_day\n",
       "0         2019-01-01 00:00:18     January           Tuesday                  0\n",
       "1         2019-01-01 00:00:44     January           Tuesday                  0\n",
       "2         2019-01-01 00:00:51     January           Tuesday                  0\n",
       "3         2019-01-01 00:01:16     January           Tuesday                  0\n",
       "4         2019-01-01 00:03:06     January           Tuesday                  0\n",
       "...                       ...         ...               ...                ...\n",
       "1296670   2020-06-21 12:12:08        June            Sunday                 12\n",
       "1296671   2020-06-21 12:12:19        June            Sunday                 12\n",
       "1296672   2020-06-21 12:12:32        June            Sunday                 12\n",
       "1296673   2020-06-21 12:13:36        June            Sunday                 12\n",
       "1296674   2020-06-21 12:13:37        June            Sunday                 12\n",
       "\n",
       "[1296675 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming 'trans_date_trans_time' into day of week, hour of day, and month\n",
    "X['trans_date_trans_time'] = pd.to_datetime(X['trans_date_trans_time'])\n",
    "X['trans_month'] = X['trans_date_trans_time'].dt.month_name()\n",
    "X['trans_day_of_week'] = X['trans_date_trans_time'].dt.day_name()\n",
    "X['trans_hour_of_day'] = X['trans_date_trans_time'].dt.hour\n",
    "\n",
    "#X = X.drop(columns='trans_date_trans_time')\n",
    "\n",
    "X[['trans_date_trans_time', 'trans_month', 'trans_day_of_week', 'trans_hour_of_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c267a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
