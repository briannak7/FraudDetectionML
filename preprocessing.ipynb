{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6c25d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "59e9055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in our training data and take the first column as the index column\n",
    "fraud_train = pd.read_csv('fraudTrain.csv', index_col=0)\n",
    "\n",
    "# split the training data into x and y\n",
    "X = fraud_train.drop(columns='is_fraud')\n",
    "y = fraud_train['is_fraud']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "652b9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   cc_num                 1296675 non-null  int64  \n",
      " 2   merchant               1296675 non-null  object \n",
      " 3   category               1296675 non-null  object \n",
      " 4   amt                    1296675 non-null  float64\n",
      " 5   first                  1296675 non-null  object \n",
      " 6   last                   1296675 non-null  object \n",
      " 7   gender                 1296675 non-null  object \n",
      " 8   street                 1296675 non-null  object \n",
      " 9   city                   1296675 non-null  object \n",
      " 10  state                  1296675 non-null  object \n",
      " 11  zip                    1296675 non-null  int64  \n",
      " 12  lat                    1296675 non-null  float64\n",
      " 13  long                   1296675 non-null  float64\n",
      " 14  city_pop               1296675 non-null  int64  \n",
      " 15  job                    1296675 non-null  object \n",
      " 16  dob                    1296675 non-null  object \n",
      " 17  trans_num              1296675 non-null  object \n",
      " 18  unix_time              1296675 non-null  int64  \n",
      " 19  merch_lat              1296675 non-null  float64\n",
      " 20  merch_long             1296675 non-null  float64\n",
      "dtypes: float64(5), int64(4), object(12)\n",
      "memory usage: 217.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94102</th>\n",
       "      <td>2019-02-25 08:24:40</td>\n",
       "      <td>374497717543058</td>\n",
       "      <td>fraud_Funk Group</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>20.00</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Hurst</td>\n",
       "      <td>F</td>\n",
       "      <td>31701 Tucker Square Suite 893</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>ND</td>\n",
       "      <td>58579</td>\n",
       "      <td>47.1709</td>\n",
       "      <td>-100.7944</td>\n",
       "      <td>1190</td>\n",
       "      <td>Designer, ceramics/pottery</td>\n",
       "      <td>1948-06-30</td>\n",
       "      <td>1595dec12f6f19ceaae9b7df0f8af5c0</td>\n",
       "      <td>1330158280</td>\n",
       "      <td>46.398331</td>\n",
       "      <td>-99.813959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198791</th>\n",
       "      <td>2019-04-12 19:50:15</td>\n",
       "      <td>4428154703770710</td>\n",
       "      <td>fraud_Prosacco, Kreiger and Kovacek</td>\n",
       "      <td>home</td>\n",
       "      <td>284.88</td>\n",
       "      <td>Brittany</td>\n",
       "      <td>Guerra</td>\n",
       "      <td>F</td>\n",
       "      <td>79209 Gary Dale</td>\n",
       "      <td>Colton</td>\n",
       "      <td>WA</td>\n",
       "      <td>99113</td>\n",
       "      <td>46.5901</td>\n",
       "      <td>-117.1692</td>\n",
       "      <td>761</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>1943-06-30</td>\n",
       "      <td>0ed26b649ed0fce94d8e632b7208dea0</td>\n",
       "      <td>1334260215</td>\n",
       "      <td>45.687331</td>\n",
       "      <td>-117.488135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238587</th>\n",
       "      <td>2020-05-31 21:50:53</td>\n",
       "      <td>213148039875802</td>\n",
       "      <td>fraud_Langworth, Boehm and Gulgowski</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>5.07</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Jacobs</td>\n",
       "      <td>F</td>\n",
       "      <td>034 Kimberly Mountains</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>FL</td>\n",
       "      <td>33510</td>\n",
       "      <td>27.9551</td>\n",
       "      <td>-82.2966</td>\n",
       "      <td>79613</td>\n",
       "      <td>Environmental consultant</td>\n",
       "      <td>1978-11-30</td>\n",
       "      <td>7096316ec1a4b261e8613013827abae7</td>\n",
       "      <td>1370037053</td>\n",
       "      <td>27.254081</td>\n",
       "      <td>-81.974799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        trans_date_trans_time            cc_num  ...  merch_lat  merch_long\n",
       "94102     2019-02-25 08:24:40   374497717543058  ...  46.398331  -99.813959\n",
       "198791    2019-04-12 19:50:15  4428154703770710  ...  45.687331 -117.488135\n",
       "1238587   2020-05-31 21:50:53   213148039875802  ...  27.254081  -81.974799\n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at our data\n",
    "X.info()\n",
    "X.sample(3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f775f22",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## 1. Finding and Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b01dbe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what columns have null values?\n",
    "sum(X.isnull().sum()) + y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5586ff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what columns have missing/na values?\n",
    "sum(X.isna().sum()) + y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42263e5e",
   "metadata": {},
   "source": [
    "No handling of missing values is required as there are no missing values in our training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33756333",
   "metadata": {},
   "source": [
    "## 2. Finding and Removing Outliers\n",
    "\n",
    "Removing outliers is an important part of preprocessing as outliers can:\n",
    "- distort data analysis \n",
    "- reduce machine learning model accuracy and generalization\n",
    "- impact visual data, skewing the scale \n",
    "- more?\n",
    "\n",
    "For numeric columns (those with an integer or float data type), I chose to use the [Interquartile Range Method](https://online.stat.psu.edu/stat200/lesson/3/3.2) of finding and removing outliers. \n",
    "\n",
    "**Categorical, or ...**\n",
    "\n",
    "## FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "16038acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the numerical columns\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_cols\n",
    "\n",
    "# calculate the IQR lower and upper bounds for each numerical column\n",
    "def iqr_bounds(col):\n",
    "    Q1 = col.quantile(0.25)\n",
    "    Q3 = col.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bb56025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_num: lower=-6513275846701038.0, upper=1.133557426847813e+16\n",
      "amt: lower=-100.58499999999998, upper=193.375\n",
      "zip: lower=-42470.5, upper=140749.5\n",
      "lat: lower=23.640650000000004, upper=52.920249999999996\n",
      "long: lower=-121.75800000000001, upper=-55.198\n",
      "city_pop: lower=-28634.5, upper=49705.5\n",
      "unix_time: lower=1307798793.0, upper=1390337325.0\n",
      "merch_lat: lower=23.898184000000008, upper=52.79255199999999\n",
      "merch_long: lower=-121.88799400000002, upper=-55.24607799999998\n"
     ]
    }
   ],
   "source": [
    "# lets look at the lower and upper bounds for each numerical column\n",
    "for col in num_cols:\n",
    "    lower, upper = iqr_bounds(X[col])\n",
    "    print(f\"{col}: lower={lower}, upper={upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a261fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc_num: 118789 outliers\n",
      "amt: 67290 outliers\n",
      "zip: 0 outliers\n",
      "lat: 4679 outliers\n",
      "long: 49922 outliers\n",
      "city_pop: 242674 outliers\n",
      "unix_time: 0 outliers\n",
      "merch_lat: 4967 outliers\n",
      "merch_long: 41994 outliers\n"
     ]
    }
   ],
   "source": [
    "# how many outliers are there in each numerical column?\n",
    "for col in num_cols:\n",
    "    lower, upper = iqr_bounds(X[col])\n",
    "    outliers = fraud_train[(fraud_train[col] < lower) | (fraud_train[col] > upper)]\n",
    "    print(f\"{col}: {len(outliers)} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdddcae0",
   "metadata": {},
   "source": [
    "Some of the numerical columns wouldn't make sense to have outlier values, such as cc_num. However, I won't be dropping any of the rows with outlier values before training a model on the dataset, as I'm interested in comparing how the model performs with and without the outlier values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6447216",
   "metadata": {},
   "source": [
    "### 3. Feature Selection & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d0dbf",
   "metadata": {},
   "source": [
    "Before training a model, I want to get a good idea of our data. I ask myself questions such as *\"is this information redundnat?\"* or *\"can this data be generalized or are all values unique?\"*. If the answer to either question is yes, it is usually best to remove the column. However, sometimes there is information that we can extract from the noisy column that may not be redundant and can be generalized or categorized. \n",
    "\n",
    "\n",
    "One example in our data is the trans_time_trans_date column. At the moment, this column may not help us detect fraud very well since almost every entry is unqiue (as shown below), but there is some interesting information we may want to look at within the column. Information such as day of the week or the hour in which the transaction took place could help us identify fraudulent transactions more accurately. Based on our columns printed below, I plan to extract the following information:\n",
    "\n",
    "## FIX ME:\n",
    "- cc_num: number of transaction in past **X time** (days? weeks? months?) for each credit card number\n",
    "- trans_date_trans_time: month, day of week, and hour of transaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "755eb76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.31% of the values in trans_date_trans_time are unique.\n",
      "0.08% of the values in cc_num are unique.\n",
      "0.05% of the values in merchant are unique.\n",
      "0.0% of the values in category are unique.\n",
      "4.08% of the values in amt are unique.\n",
      "0.03% of the values in first are unique.\n",
      "0.04% of the values in last are unique.\n",
      "0.0% of the values in gender are unique.\n",
      "0.08% of the values in street are unique.\n",
      "0.07% of the values in city are unique.\n",
      "0.0% of the values in state are unique.\n",
      "0.07% of the values in zip are unique.\n",
      "0.07% of the values in lat are unique.\n",
      "0.07% of the values in long are unique.\n",
      "0.07% of the values in city_pop are unique.\n",
      "0.04% of the values in job are unique.\n",
      "0.07% of the values in dob are unique.\n",
      "100.0% of the values in trans_num are unique.\n",
      "98.31% of the values in unix_time are unique.\n",
      "96.23% of the values in merch_lat are unique.\n",
      "98.39% of the values in merch_long are unique.\n"
     ]
    }
   ],
   "source": [
    "def unique_percentage(column):\n",
    "    return (len(X[column].unique())) / len(X[column]) * 100\n",
    "\n",
    "for column in X.columns:\n",
    "    print(f'{round(unique_percentage(column),2)}% of the values in {column} are unique.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "de5f3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming 'trans_date_trans_time' into day of week, hour of day, and month\n",
    "X['trans_date_trans_time'] = pd.to_datetime(X['trans_date_trans_time'])\n",
    "X['trans_month'] = X['trans_date_trans_time'].dt.month_name()\n",
    "X['trans_day_of_week'] = X['trans_date_trans_time'].dt.day_name()\n",
    "X['trans_hour_of_day'] = X['trans_date_trans_time'].dt.hour\n",
    "\n",
    "\n",
    "# X[['trans_month', 'trans_day_of_week', 'trans_hour_of_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3fec3d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_day_of_week</th>\n",
       "      <th>trans_hour_of_day</th>\n",
       "      <th>trans_date</th>\n",
       "      <th>trans_count_per_day</th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>January</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num  ... trans_count_per_day birth_year\n",
       "0   2019-01-01 00:00:18  2703186189652095  ...                   3       1988\n",
       "1   2019-01-01 00:00:44      630423337322  ...                  10       1978\n",
       "2   2019-01-01 00:00:51    38859492057661  ...                   1       1962\n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull month, day, year from trans_date_trans_time into one value\n",
    "X['trans_date'] = pd.to_datetime(X['trans_date_trans_time']).dt.date\n",
    "\n",
    "# count the number of transactions per credit card number per day and add it as a new column\n",
    "X['trans_count_per_day'] = X.groupby(['cc_num', 'trans_date'])['trans_date_trans_time'].transform('count')\n",
    "\n",
    "# extracting the year from the dob column\n",
    "X['birth_year'] = pd.to_datetime(X['dob']).dt.year\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311641c0",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "- ~~need to remove fraud_ from merchant~~ - and explain!\n",
    "- category has pos and net (maybe online vs in store?)\n",
    "- ~~dob to date~~\n",
    "- job into less buckets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fa53889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>merchant</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848453</th>\n",
       "      <td>misc_pos</td>\n",
       "      <td>Surveyor, land/geomatics</td>\n",
       "      <td>fraud_Gutmann-Upton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389650</th>\n",
       "      <td>health_fitness</td>\n",
       "      <td>Trade mark attorney</td>\n",
       "      <td>fraud_Graham and Sons</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182918</th>\n",
       "      <td>health_fitness</td>\n",
       "      <td>Trade mark attorney</td>\n",
       "      <td>fraud_Conroy, Balistreri and Gorczany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776424</th>\n",
       "      <td>kids_pets</td>\n",
       "      <td>Information systems manager</td>\n",
       "      <td>fraud_Bode-Rempel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878564</th>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>Physicist, medical</td>\n",
       "      <td>fraud_Kilback LLC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category  ... is_fraud\n",
       "848453        misc_pos  ...        0\n",
       "389650  health_fitness  ...        0\n",
       "182918  health_fitness  ...        0\n",
       "776424       kids_pets  ...        0\n",
       "878564     grocery_pos  ...        0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_train[['category', 'job', \n",
    "             'merchant', 'is_fraud']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3d6f8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing 'fraud_' from the merchant column\n",
    "X['merchant'] = X['merchant'].str.replace('fraud_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "49f2ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count    Dtype \n",
      "---  ------             --------------    ----- \n",
      " 0   merchant           1296675 non-null  object\n",
      " 1   category           1296675 non-null  object\n",
      " 2   first              1296675 non-null  object\n",
      " 3   last               1296675 non-null  object\n",
      " 4   gender             1296675 non-null  object\n",
      " 5   street             1296675 non-null  object\n",
      " 6   city               1296675 non-null  object\n",
      " 7   state              1296675 non-null  object\n",
      " 8   job                1296675 non-null  object\n",
      " 9   dob                1296675 non-null  object\n",
      " 10  trans_num          1296675 non-null  object\n",
      " 11  trans_month        1296675 non-null  object\n",
      " 12  trans_day_of_week  1296675 non-null  object\n",
      " 13  trans_date         1296675 non-null  object\n",
      "dtypes: object(14)\n",
      "memory usage: 148.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# all object columns\n",
    "X.select_dtypes(include=['object']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f735a0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   cc_num               1296675 non-null  int64  \n",
      " 1   amt                  1296675 non-null  float64\n",
      " 2   zip                  1296675 non-null  int64  \n",
      " 3   lat                  1296675 non-null  float64\n",
      " 4   long                 1296675 non-null  float64\n",
      " 5   city_pop             1296675 non-null  int64  \n",
      " 6   unix_time            1296675 non-null  int64  \n",
      " 7   merch_lat            1296675 non-null  float64\n",
      " 8   merch_long           1296675 non-null  float64\n",
      " 9   trans_hour_of_day    1296675 non-null  int32  \n",
      " 10  trans_count_per_day  1296675 non-null  int64  \n",
      " 11  birth_year           1296675 non-null  int32  \n",
      "dtypes: float64(5), int32(2), int64(5)\n",
      "memory usage: 118.7 MB\n"
     ]
    }
   ],
   "source": [
    "# all numerical columns\n",
    "X.select_dtypes(include=['float64', 'int64', 'int32']).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce473b",
   "metadata": {},
   "source": [
    "Looking at all the object Dtype columns, I am most interested in keeping the gender, state, job, birth_year, trans_month, and trans_day_of_week. \n",
    "\n",
    "I am opting to remove the street, zip, and city columns, as I think training on the state will be enough. If, after we've trained a model and looked at the feature coefficients, the state in which a person lives carries a high probablity of a fraudulent transaction, we can train a new model to take into consideration the mroe in depth locational features. \n",
    "\n",
    "Similarly, I am omitting the cc_number, first, last, dob, lat, long, trans_num, merch_lat, merch_long, and trans_date_trans_time. Removing these columns will reduces noise in our data which will increase the accuracy and reliability of our model.\n",
    "\n",
    "The following columns are dropped from our dataset below:\n",
    "- cc_num  \n",
    "- first  \n",
    "- last  \n",
    "- street  \n",
    "- city \n",
    "- dob \n",
    "- zip  \n",
    "- lat\n",
    "- long\n",
    "- merch_lat\n",
    "- merch_long\n",
    "- trans_num  \n",
    "- trans_date_trans_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "47eff5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count    Dtype  \n",
      "---  ------               --------------    -----  \n",
      " 0   merchant             1296675 non-null  object \n",
      " 1   category             1296675 non-null  object \n",
      " 2   amt                  1296675 non-null  float64\n",
      " 3   gender               1296675 non-null  object \n",
      " 4   state                1296675 non-null  object \n",
      " 5   city_pop             1296675 non-null  int64  \n",
      " 6   job                  1296675 non-null  object \n",
      " 7   dob                  1296675 non-null  object \n",
      " 8   trans_month          1296675 non-null  object \n",
      " 9   trans_day_of_week    1296675 non-null  object \n",
      " 10  trans_hour_of_day    1296675 non-null  int32  \n",
      " 11  trans_date           1296675 non-null  object \n",
      " 12  trans_count_per_day  1296675 non-null  int64  \n",
      " 13  birth_year           1296675 non-null  int32  \n",
      "dtypes: float64(1), int32(2), int64(2), object(9)\n",
      "memory usage: 138.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# dropping all columns we are not interested in\n",
    "X = X.drop(columns=['cc_num',\n",
    "                    'first',\n",
    "                    'last',\n",
    "                    'street',\n",
    "                    'city',\n",
    "                    'zip',\n",
    "                    'lat',\n",
    "                    'long',\n",
    "                    'trans_num',\n",
    "                    'unix_time',\n",
    "                    'merch_lat',\n",
    "                    'merch_long',\n",
    "                    'trans_date_trans_time'\n",
    "                    ])\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f133ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# X_ohe = ohe.fit_transform(X.select_dtypes(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37472564",
   "metadata": {},
   "source": [
    "### 4. Correlation Analysis\n",
    "\n",
    "Before we analyze the correlation between all numerical columns, we need to convert categorical features into numerical features without heirarchy. To do this, I will use sci-kit learn's [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
